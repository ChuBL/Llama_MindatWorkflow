{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (6.0.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: pyvis in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.3.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pyvis) (8.28.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pyvis) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pyvis) (3.3.0)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pyvis) (3.4.1)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jinja2>=2.9.6->pyvis) (3.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Requirement already satisfied: folium in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.17.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from folium) (0.8.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from folium) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from folium) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jinja2>=2.9->folium) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->folium) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->folium) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->folium) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->folium) (2024.8.30)\n",
      "Requirement already satisfied: ipympl in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.9.4)\n",
      "Requirement already satisfied: ipython-genutils in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (0.2.0)\n",
      "Requirement already satisfied: ipython<9 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (8.28.0)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (8.1.5)\n",
      "Requirement already satisfied: matplotlib<4,>=3.4.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (3.9.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (1.26.4)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (10.4.0)\n",
      "Requirement already satisfied: traitlets<6 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipympl) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipython<9->ipympl) (4.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from matplotlib<4,>=3.4.0->ipympl) (2.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pexpect>4.3->ipython<9->ipympl) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9->ipympl) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4,>=3.4.0->ipympl) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from stack-data->ipython<9->ipympl) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from stack-data->ipython<9->ipympl) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from stack-data->ipython<9->ipympl) (0.2.3)\n",
      "Requirement already satisfied: langchain-experimental in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-experimental) (0.3.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-experimental) (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.1.134)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.15.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.6->langchain-experimental) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.2.0)\n",
      "Requirement already satisfied: langgraph in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.2.35)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.39 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langgraph) (0.3.10)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langgraph) (2.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (0.1.134)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.2.39->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.2.39->langgraph) (2.23.4)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (4.6.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.0.6)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2.2.3)\n",
      "Requirement already satisfied: langchain_openai in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain_openai) (0.3.10)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain_openai) (1.51.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (0.1.134)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain_openai) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
      "Requirement already satisfied: openmindat in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (0.0.9)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openmindat) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openmindat) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from openmindat) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->openmindat) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->openmindat) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->openmindat) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ollama2/lib/python3.12/site-packages (from requests->openmindat) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "# %%capture --no-stderr\n",
    "!pip install PyYAML==6.0.2\n",
    "!pip install matplotlib==3.9.2\n",
    "!pip install networkx==3.4.1\n",
    "!pip install pyvis==0.3.2\n",
    "!pip install folium==0.17.0\n",
    "!pip install ipympl==0.9.4\n",
    "!pip install langchain==0.3.3\n",
    "!pip install langchain-core==0.3.10\n",
    "!pip install langchain-community==0.3.2\n",
    "!pip install langchain-ollama==0.2.0\n",
    "!pip install langchain-experimental==0.3.2\n",
    "!pip install langgraph==0.2.35\n",
    "!pip install langchain-openai==0.2.2\n",
    "!pip install openmindat==0.0.9\n",
    "\n",
    "# !pip install peft==0.13.2 transformers==4.46.0 torch==2.5.0\n",
    "# !pip install unsloth==2024.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINDAT_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Function to read YAML file\n",
    "def read_yaml(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            try:\n",
    "                content = yaml.safe_load(file)\n",
    "                return content\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(f\"Error reading YAML file: {exc}\")\n",
    "                return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to write YAML file\n",
    "def write_yaml(file_path, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        try:\n",
    "            yaml.dump(data, file, default_flow_style=False)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(f\"Error writing YAML file: {exc}\")\n",
    "\n",
    "# Path to your YAML file\n",
    "yaml_file_path = '.apikey.yaml'\n",
    "\n",
    "# Read YAML file\n",
    "config = read_yaml(yaml_file_path)\n",
    "\n",
    "# Check if the config is loaded, otherwise prompt for input\n",
    "if config and 'api_key' in config:\n",
    "    os.environ[\"MINDAT_API_KEY\"] = config['api_key']\n",
    "else:\n",
    "    mindat_api_key = input(\"YAML file not found or 'mindat' key missing. Please enter your MINDAT_API_KEY: \")\n",
    "    os.environ[\"MINDAT_API_KEY\"] = mindat_api_key\n",
    "    \n",
    "    # Save the API key to YAML file\n",
    "    new_config = {'api_key': mindat_api_key}\n",
    "    write_yaml(yaml_file_path, new_config)\n",
    "    print(f\"API key saved to {yaml_file_path}.\")\n",
    "\n",
    "print(\"MINDAT_API_KEY is set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                ID              SIZE      MODIFIED    \n",
      "gene21d4/llama_3.1_instruct_8b_openmindat:latest    45ba34c46e72    4.9 GB    9 days ago     \n",
      "llama-3.1-instruct-8b-openmindat:latest             45ba34c46e72    4.9 GB    9 days ago     \n",
      "llama3.1:8b-instruct-q4_K_M                         46e0c10c039e    4.9 GB    10 days ago    \n",
      "llama3.1:latest                                     42182419e950    4.7 GB    2 weeks ago    \n",
      "llama3.2:3b                                         a80c4f17acd5    2.0 GB    3 weeks ago    \n",
      "nomic-embed-text:latest                             0a109f422b47    274 MB    3 weeks ago    \n",
      "mistral:latest                                      f974a74358d6    4.1 GB    3 weeks ago    \n",
      "llama3:latest                                       365c0bd3c000    4.7 GB    3 weeks ago    \n",
      "llama2:latest                                       78e26419b446    3.8 GB    3 weeks ago    \n",
      "gemma:latest                                        a72c7f4d0a15    5.0 GB    3 weeks ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "# comment out the first line to download the models\n",
    "!ollama pull llama3.1:8b-instruct-q4_K_M\n",
    "!ollama pull gene21d4/llama_3.1_instruct_8b_openmindat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# model = OllamaFunctions(\n",
    "#     model=\"llama3:8b\", \n",
    "#     format=\"json\"\n",
    "#     )\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:8b-instruct-q4_K_M\", format='json')#, temperature=0)\n",
    "\n",
    "supervisor_llm = ChatOllama(model=\"gene21d4/llama_3.1_instruct_8b_openmindat:latest\", format='json', num_predict = 64)\n",
    "\n",
    "# llm = ChatOllama(model=\"llama3:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Agent Supervisor\n",
    "\n",
    "It will use function calling to choose the next worker node OR finish processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import re\n",
    "\n",
    "# members = [\"Collector\", \"Network_Plotter\"]\n",
    "\n",
    "# members = [\"GEOMATERIAL_COLLECTOR\", \"LOCALITY_COLLECTOR\", \"HISTOGRAM_PLOTTER\", \"NETWORK_PLOTTER\", \"HEATMAP_PLOTTER\"]\n",
    "\n",
    "members = [\"GEOMATERIAL_COLLECTOR\", \"LOCALITY_COLLECTOR\", \"NETWORK_PLOTTER\", \"HEATMAP_PLOTTER\"]\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "# Schema for structured response\n",
    "class NextDecision(BaseModel):\n",
    "    next: str = Field(description=\"Choose one from {options}\")\n",
    "    supervisor_reason: str = Field(description=\"The reason for choosing the next disicion. Please respond with 'next' and 'supervisor_reason' keys, no 'tool' or 'tool_input' needed\")\n",
    "    # model_construct: str = Field(description=\"placeholder\")\n",
    "\n",
    "supervisor_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a supervisor managing a the team members: {members}. fulfill the user request.\\n\n",
    "    Respond with FINISH if the user request is fulfilled. \\n\n",
    "\n",
    "    # Team Members\n",
    "\n",
    "    ## Data Collectors\n",
    "    - **GEOMATERIAL_COLLECTOR**\n",
    "    - Collects mineral datasets with conditional filters\n",
    "    - Required for network visualization\n",
    "\n",
    "    - **LOCALITY_COLLECTOR**\n",
    "    - Collects mineral locality data by country\n",
    "    - Required for heatmap visualization\n",
    "\n",
    "    ## Visualization Specialists\n",
    "    - **NETWORK_PLOTTER**\n",
    "    - Creates network visualizations\n",
    "    - Depends on GEOMATERIAL_COLLECTOR's data\n",
    "\n",
    "    - **HEATMAP_PLOTTER**\n",
    "    - Creates heatmap visualizations\n",
    "    - Depends on LOCALITY_COLLECTOR's data\n",
    "\n",
    "    # Workflow Decision Rules\n",
    "\n",
    "    ## Check Workflow Progress\n",
    "    1. Look for workflow steps in input (e.g., \"Step 0, Supervisor node: LOCALITY_COLLECTOR\")\n",
    "    2. Verify if data collection is completed (check for success messages)\n",
    "\n",
    "    ## Next Step Selection\n",
    "    1. If NO workflow steps present:\n",
    "    - For mineral analysis → Start with GEOMATERIAL_COLLECTOR\n",
    "    - For locality analysis → Start with LOCALITY_COLLECTOR\n",
    "\n",
    "    2. If workflow shows data collection complete and user requested visualization:\n",
    "    - After GEOMATERIAL_COLLECTOR → Proceed to NETWORK_PLOTTER\n",
    "    - After LOCALITY_COLLECTOR → Proceed to HEATMAP_PLOTTER\n",
    "\n",
    "    3. If workflow shows incomplete/failed collection:\n",
    "    - Retry with appropriate collector before visualization\n",
    "\n",
    "    4. If request is fully full filled or out of scope of the team member:\n",
    "    - Go FINISH\n",
    "\n",
    "    Please revise your response according to {errors} if present.\n",
    "\n",
    "    Messages : {messages} \\n\n",
    "    Given the conversation above, who should act next?\n",
    "    Or should we FINISH? Select one of: {options}\n",
    "    \n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"members\",\"messages\",\"options\", \"errors\"],\n",
    ")\n",
    "\n",
    "\n",
    "# llm = OllamaFunctions(model=\"llama3:8b\", format='json')\n",
    "\n",
    "structured_llm = supervisor_llm# .with_structured_output(NextDecision)\n",
    "supervisor_chain = supervisor_prompt | structured_llm\n",
    "\n",
    "# llm_with_tools = llm.bind_tools([NextDecision])\n",
    "# supervisor_chain = supervisor_prompt | llm_with_tools\n",
    "\n",
    "errors = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supervisor test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "import re\n",
    "import json\n",
    "\n",
    "structured_llm = supervisor_llm# .with_structured_output(NextDecision)\n",
    "supervisor_chain = supervisor_prompt | structured_llm\n",
    "\n",
    "\n",
    "messages = \"\"\"User: i want you to plot network visualization for carbon and oxygen mineral but without Magnesium\n",
    "Step 0, Supervisor node: COLLECTOR\n",
    "Step 1, Collector node: The Collector node successfully saved the dataset to /Users/blc/pyspace/Git_Mindat/mindatxllm/content/mindat_data/geomaterials_data.json\"\"\"\n",
    "\n",
    "errors = ''\n",
    "retry_tolerance = 5\n",
    "\n",
    "def parse_required_keys_from_llm_response(llm_response):\n",
    "    # 定义所需的键\n",
    "    required_keys = [\"next\", \"supervisor_reason\"]\n",
    "    extracted_data = {}\n",
    "\n",
    "    # 使用正则表达式匹配所有键值对，匹配键和值为双引号或单引号包裹的内容\n",
    "    for key in required_keys:\n",
    "        pattern = rf'[\"]({key})[\"](?:\\s*:\\s*)[\"](.*?)[\"]'\n",
    "        match = re.search(pattern, llm_response, re.DOTALL)\n",
    "        if match:\n",
    "            extracted_data[match.group(1)] = match.group(2)\n",
    "\n",
    "    # 检查是否所有键都被提取\n",
    "    if len(extracted_data) == len(required_keys):\n",
    "        return json.loads(json.dumps(extracted_data))\n",
    "    else:\n",
    "        missing_keys = set(required_keys) - set(extracted_data.keys())\n",
    "        raise ValueError(f\"Missing keys in LLM response: {missing_keys}\")\n",
    "\n",
    "for retry_count in range(retry_tolerance):\n",
    "    print(f\"Retrying({retry_count + 1}/{retry_tolerance})\")\n",
    "    try:\n",
    "        result = supervisor_chain.invoke({\n",
    "            \"members\": members, \n",
    "            \"messages\": str(messages), \n",
    "            \"options\": options, \n",
    "            \"errors\": errors,\n",
    "            # \"supervisor_example1\": supervisor_example1,\n",
    "            # \"supervisor_example2\": supervisor_example2,\n",
    "            # \"supervisor_example3\": supervisor_example3,\n",
    "        })\n",
    "\n",
    "        print(\"supervisor output: \", result)\n",
    "\n",
    "\n",
    "        # 解析 JSON 字符串为字典\n",
    "        content_dict = json.loads(result.content)\n",
    "\n",
    "        # 安全地获取 'nextStep' 和 'next'\n",
    "        print(\"content:\", content_dict)\n",
    "        print(\"next in content:\", content_dict.get('nextStep'), content_dict.get('next'))\n",
    "\n",
    "        break\n",
    "\n",
    "        result_next = result.next  # Access the 'next' attribute of the NextDecision object\n",
    "        if result_next.upper() in options:\n",
    "            break\n",
    "        else:\n",
    "            jargon_errors = f\"{result_next} not in {options}, please try again.\"\n",
    "            errors = jargon_errors\n",
    "            print(\"Jargon errors: \", jargon_errors)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(\"Parsing...\")\n",
    "        print(e)\n",
    "        print(parse_required_keys_from_llm_response(str(e)))\n",
    "        # raise SystemExit(\"Terminating execution\")\n",
    "    except (KeyError, IndexError, AttributeError) as e:\n",
    "        error_type = type(e).__name__\n",
    "        errors = f\"{error_type}: {str(e)}\"\n",
    "        print(errors)\n",
    "\n",
    "print(\"supervisor test done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Action Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geomaterial Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "# from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# Import things that are needed generically\n",
    "\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from openmindat import GeomaterialSearchRetriever\n",
    "import json, pprint\n",
    "\n",
    "\n",
    "# tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# This executes code locally, which can be unsafe\n",
    "# python_repl_tool = PythonREPLTool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union, Optional\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from openmindat import GeomaterialRetriever\n",
    "from pathlib import Path\n",
    "\n",
    "class GeomaterialQueryDict(BaseModel):\n",
    "    ima: Optional[bool] = Field(description=\"Only IMA-approved names, should be True by default\")\n",
    "    hardness_min: Optional[Union[float,str]] = Field(description=\"Mohs hardness from, leave as '' if necessary\")\n",
    "    hardness_max: Optional[Union[float,str]] = Field(description=\"Mohs hardness to, leave as '' if necessary\")\n",
    "    crystal_system: Optional[list[str]] = Field(description=\"Optional Crystal system (csystem): multiple choice (OR), Items Enum: 'Amorphous','Hexagonal','Icosahedral','Isometric','Monoclinic','Orthorhombic','Tetragonal','Triclinic','Trigonal', leave as [] if not required\")\n",
    "    elements_inc: Optional[str] = Field(description=\"Chemical elements must include, e.g., 'Fe,Cu', leave as '' if necessary\")\n",
    "    elements_exc: Optional[str] = Field(description=\"Chemical elements must exclude, e.g., 'Fe,Cu', leave as '' if necessary\")\n",
    "    expand: Optional[str] = Field(description=\"Expand the search scope with 'locality', leave as '' if necessary\")\n",
    "\n",
    "\n",
    "# class MindatCollectorInput(BaseModel):\n",
    "#     name: str =  Field(description=\"the name of the tool\")\n",
    "#     args: MindatQueryDict = Field(description=\"a json with key-value pairs for the querying dict\")\n",
    "\n",
    "\n",
    "# class MindatCollectorInput(BaseModel):\n",
    "#     query: MindatQueryDict = Field(description=\"\"\"Example dicts, all of the keys are optional, omit the keys without values if necessary:\n",
    "# {\n",
    "#     \"ima\": True,  # Only IMA-approved names, should be True by default\n",
    "#     \"hardness_min\": 1.0,  # Mohs hardness from 1, , leave as '' if necessary\n",
    "#     \"hardness_max\": 10.0,  # Mohs hardness to 10, , leave as '' if necessary\n",
    "#     \"crystal_system\": [\"Hexagonal\"],  # Hexagonal crystal system, , leave as []  if not required\n",
    "#     \"elements_inc\": \"Ag,H\",  # Must include Gold (Ag) and Hxygen (H), , leave as '' if necessary\n",
    "#     \"elements_exc\": \"Fe\",  # Exclude Iron (Fe), , leave as '' if necessary\n",
    "#     \"expand\": \"locality\", # Expand the search scope with 'locality', , leave as '' if necessary\n",
    "# }\n",
    "# \"\"\")\n",
    "\n",
    "def geomaterial_collector_function(query: dict):\n",
    "    print(\"====in geomaterial collecting function====\")\n",
    "    # if 'query_dict' in query:\n",
    "    #     query = query['query_dict']\n",
    "    # original_dict = query.dict()\n",
    "    original_dict = query\n",
    "    # import sys\n",
    "    # sys.exit()\n",
    "\n",
    "    # Filter out keys with empty values\n",
    "    filtered_dict = {key: value for key, value in original_dict.items() if value and value != '[]'}\n",
    "   \n",
    "    if 'expand' in filtered_dict:\n",
    "        filtered_dict.update({'page_size': 200})\n",
    "    # filtered_query = {k: v for k, v in filtered_dict.items() if v}\n",
    "    print(filtered_dict)\n",
    "\n",
    "    gr = GeomaterialRetriever()\n",
    "    gr._params.update(filtered_dict)\n",
    "    saving_path = Path(\"./mindat_data\").resolve()\n",
    "    file_name = \"geomaterial_data\"\n",
    "    gr.saveto(saving_path, file_name)\n",
    "    \n",
    "    file_path = Path(saving_path, file_name + '.json')\n",
    "\n",
    "    if geomaterial_checker(file_path):\n",
    "        return f\"The Geomaterial Collector node has successfully saved the dataset to {file_path}\"\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def geomaterial_checker(FILE_PATH: str):\n",
    "    '''Check if the download request is valid'''\n",
    "    with open(FILE_PATH, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        if 0 == len(data[\"results\"]):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "# mindat_collect = StructuredTool.from_function(\n",
    "#     func=mindat_collector_function,\n",
    "#     name=\"MindatCollect\",\n",
    "#     description=\"\"\"useful for collecting mindat mineral information and saving as json, will return the file path.\n",
    "#     \"\"\",\n",
    "#     args_schema=MindatCollectorInput\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elements_exc': 'Mg', 'elements_inc': 'C,Fe', 'expand': 'locality', 'ima': 'True', 'page_size': 200}\n"
     ]
    }
   ],
   "source": [
    "sample_dict = {'crystal_system': '[]', 'elements_exc': 'Mg', 'elements_inc': 'C,Fe', 'expand': 'locality', 'ima': 'True', 'page_size': 200}\n",
    "filtered_dict = {key: value for key, value in sample_dict.items() if value and value != '[]'}\n",
    "print(filtered_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_query1 = {\n",
    "  # \"name\": \"COLLECTOR\",\n",
    "  #\"args\": {\n",
    "    \"ima\": True,\n",
    "    \"elements_inc\": \"Cu\",\n",
    "    \"hardness_min\": \"\",\n",
    "    \"hardness_max\": \"\",\n",
    "    \"crystal_system\": [],\n",
    "    \"elements_exc\": \"\"\n",
    "  #}\n",
    "}\n",
    "example_query2 = {\n",
    "  # \"name\": \"COLLECTOR\",\n",
    "  #\"args\": {\n",
    "    \"ima\": True,\n",
    "    \"elements_inc\": \"Ag,H\",\n",
    "    \"hardness_min\": 1.0,\n",
    "    \"hardness_max\": 10.0,\n",
    "    \"crystal_system\": [\"Hexagonal\"],\n",
    "    \"elements_exc\": \"Fe\"\n",
    "  #}\n",
    "}\n",
    "example_query3 = {\n",
    "  # \"name\": \"COLLECTOR\",\n",
    "  #\"args\": {\n",
    "    \"ima\": True,\n",
    "    \"elements_inc\": \"Al\",\n",
    "    \"hardness_min\": \"\",\n",
    "    \"hardness_max\": \"\",\n",
    "    \"crystal_system\": [],\n",
    "    \"elements_exc\": \"Na\",\n",
    "    \"expand\": \"locality\"\n",
    "\n",
    "  #}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## collector chain\n",
    "geo_collector_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a mineral data collector for mindat api, collecting datasets for user purpose, e.g., data collecting, mineral visualization, etc.\n",
    "\n",
    "    Example dicts, all of the keys are optional \\n\n",
    "    Example 1: \"i want the copper mineral\" response: {example_query1} \\n\n",
    "    Example 2: \"I want the ima mineral with hardness from 3 to 5, in crystall hexagonal, must include silver and hydrogen, and no iron\" response: {example_query2} \\n\n",
    "    Example 3: \"Please plot the network for Aluminum minerals, but no Sodium involved\" response: {example_query3} Remember to expand with 'locality' for network visualization\\n\n",
    "    Remember use key 'expand' with value 'locality' for network visualization. Remember use key 'expand' with value 'locality' for network visualization. Remember use key 'expand' with value 'locality' for network visualization. \\n\n",
    "\n",
    "    Please use the given json example with \"name\" and \"args\" as keys\n",
    "\n",
    "    Pay attention to the error message if presents, revise your response accordingly.\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Messages : {messages} \\n\n",
    "    Errors: {errors}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"messages\", \"errors\", \"example_query1\", \"example_query2\", \"example_query3\"],\n",
    ")\n",
    "\n",
    "# llm = OllamaFunctions(model=\"llama3:8b\", format='json')\n",
    "\n",
    "# collector_structured_llm = llm.with_structured_output(MindatQueryDict)\n",
    "# collector_chain = collector_prompt | collector_structured_llm\n",
    "\n",
    "geo_collector_llm_with_tools = llm.bind_tools([GeomaterialQueryDict])\n",
    "# collector_llm_with_tools = llm.bind_tools([MindatCollectorInput])\n",
    "geo_collector_chain = geo_collector_prompt | geo_collector_llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geomaterial collector test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "sample_query = {'ima': True, 'elements_inc': 'C,O', 'elements_exc': 'Mg', 'expand': 'locality'}\n",
    "geomaterial_collector_function(sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "# healthy?\n",
    "# messages = \"\"\"User\n",
    "# plot the histogram of the elements distribution of the ima-approved mineral species with hardness between 3-5, in Hexagonal crystal system, must have Neodymium, but without sulfur\"\"\"\n",
    "\n",
    "# messages = 'I want the datasets of iron minerals but without oxygen'\n",
    "# messages = \"\"\"User: i want you to plot histogram visualization for carbon and oxygen mineral but without Magnesium\n",
    "# Step 0, Supervisor node: HISTOGRAM_PLOTTER\n",
    "# Step 1, Histogram plotter node: The file path was not a valid path, please collect the dataset first.\"\"\"\n",
    "messages = \"User: i want you to plot histogram visualization for carbon and oxygen mineral but without Magnesium\"\n",
    "errors = ''\n",
    "\n",
    "tolerance = 3\n",
    "for t in range(tolerance):\n",
    "    print(t)\n",
    "    try:\n",
    "        result = geo_collector_chain.invoke({\n",
    "                \"messages\": str(messages), \n",
    "                \"errors\": errors, \n",
    "                'example_query1': example_query1,\n",
    "                'example_query2': example_query2,\n",
    "                'example_query3': example_query3,\n",
    "                })\n",
    "        break\n",
    "    except (ValueError, IndexError, KeyError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "    \n",
    "print(result)\n",
    "print(type(result))\n",
    "\n",
    "print(result.tool_calls[0]['args'])\n",
    "geomaterial_collector_function(result.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locality Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openmindat import LocalitiesRetriever\n",
    "\n",
    "class LocalityQueryDict(BaseModel):\n",
    "    country: str = Field(description=\"The country name\")\n",
    "    # txt: str = Field(description=\"The keywords to search for localities\")\n",
    "\n",
    "\n",
    "def locality_collector_function(query: dict):\n",
    "    print(\"====in locality collecting function====\")\n",
    "    # if 'query_dict' in query:\n",
    "    #     query = query['query_dict']\n",
    "    original_dict = query\n",
    "\n",
    "    filtered_dict = {\"country\": original_dict.get('country')}\n",
    "\n",
    "    if not filtered_dict.get('country'):\n",
    "        return False\n",
    "\n",
    "    print(filtered_dict)\n",
    "\n",
    "    lr = LocalitiesRetriever()\n",
    "    lr._params.update(filtered_dict)\n",
    "    saving_path = Path(\"./mindat_data\").resolve()\n",
    "    file_name = \"locality_data\"\n",
    "\n",
    "    lr.saveto(saving_path, file_name)\n",
    "\n",
    "    file_path = Path(saving_path, file_name + '.json')\n",
    "\n",
    "    if locality_checker(file_path):\n",
    "        return f\"The Locality Colector node has successfully saved the dataset to {file_path}\"\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def locality_checker(FILE_PATH: str):\n",
    "    '''Check if the download request is valid'''\n",
    "    with open(FILE_PATH, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        if 0 == len(data[\"results\"]):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_loc_query1 = {\n",
    "  \"country\": \"Brazil\"\n",
    "}\n",
    "example_loc_query2 = {\n",
    "  \"country\": \"Canada\"\n",
    "}\n",
    "example_loc_query3 = {\n",
    "  # \"name\": \"COLLECTOR\",\n",
    "  #\"args\": {\n",
    "    \"country\": \"\"\n",
    "  #}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "## collector chain\n",
    "loc_collector_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a mineral locality data collector for mindat api, collecting locality datasets for user purpose, e.g., data collecting, create heatmap visualization, etc.\\n\n",
    "\n",
    "    You should only retrieve the datasets for 1. locality datasets retrieval 2. heatmap visualization creation.\n",
    "\n",
    "    Example dicts, all of the keys are optional \\n\n",
    "    Example 1: \"i want the mineral records from Brazil\" response: {example_loc_query1} \\n\n",
    "    Example 2: \"plot the heatmap for Canada: {example_loc_query2} \\n\n",
    "    Example 3: \"Please plot the networdk for Norway\" response: {example_loc_query3} # Reject invalid network visualization request with empty country value\\n\n",
    "\n",
    "    Please use the given json example with \"name\" and \"args\" as keys\n",
    "\n",
    "    Pay attention to the error message if presents, revise your response accordingly.\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Messages : {messages} \\n\n",
    "    Errors: {errors}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"messages\", \"errors\", \"example_loc_query1\", \"example_loc_query2\", \"example_loc_query3\"],\n",
    ")\n",
    "\n",
    "# llm = OllamaFunctions(model=\"llama3:8b\", format='json')\n",
    "\n",
    "# collector_structured_llm = llm.with_structured_output(MindatQueryDict)\n",
    "# collector_chain = collector_prompt | collector_structured_llm\n",
    "\n",
    "loc_collector_llm_with_tools = llm.bind_tools([LocalityQueryDict])\n",
    "# collector_llm_with_tools = llm.bind_tools([MindatCollectorInput])\n",
    "loc_collector_chain = loc_collector_prompt | loc_collector_llm_with_tools\n",
    "\n",
    "\n",
    "# mindat_locality_collect = StructuredTool.from_function(\n",
    "#     func=locality_collector_function,\n",
    "#     name=\"MindatLocalitiyCollect\",\n",
    "#     description=\"\"\"useful for collecting mindat locality information and saving as json, will return the file path.\n",
    "#     \"\"\",\n",
    "#     args_schema=LocalityQueryDict\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Locality collect test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "# healthy?\n",
    "# messages = \"\"\"User\n",
    "# plot the histogram of the elements distribution of the ima-approved mineral species with hardness between 3-5, in Hexagonal crystal system, must have Neodymium, but without sulfur\"\"\"\n",
    "\n",
    "# messages = 'I want the datasets of iron minerals but without oxygen'\n",
    "# messages = \"\"\"User: i want you to plot histogram visualization for carbon and oxygen mineral but without Magnesium\n",
    "# Step 0, Supervisor node: HISTOGRAM_PLOTTER\n",
    "# Step 1, Histogram plotter node: The file path was not a valid path, please collect the dataset first.\"\"\"\n",
    "# messages = \"User: i want you to plot histogram visualization for carbon and oxygen mineral but without Magnesium\"\n",
    "\n",
    "messages = \"User: i want you to plot network visualization for Korea\"\n",
    "\n",
    "\n",
    "errors = ''\n",
    "\n",
    "tolerance = 3\n",
    "for t in range(tolerance):\n",
    "    print(t)\n",
    "    try:\n",
    "        result = loc_collector_chain.invoke({\n",
    "                \"messages\": str(messages), \n",
    "                \"errors\": errors, \n",
    "                'example_loc_query1': example_loc_query1,\n",
    "                'example_loc_query2': example_loc_query2,\n",
    "                'example_loc_query3': example_loc_query3,\n",
    "                })\n",
    "        break\n",
    "    except (ValueError, IndexError, KeyError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "    \n",
    "print(result)\n",
    "print(type(result))\n",
    "\n",
    "print(result.tool_calls[0]['args'])\n",
    "locality_collector_function(result.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HistogramInput(BaseModel):\n",
    "    file_path: str = Field(description=\"Should be a json file path of json data, leave empty if not given.\")\n",
    "    scratch_pad: str = Field(description=\"Should be your comment, e.g., the file path is not given; the process works well, etc.\")\n",
    "\n",
    "def histogram_plot_function(file_path: str):\n",
    "    df = pd.read_json(file_path)\n",
    "    df = pd.json_normalize(df['results'])\n",
    "    # Explode the DataFrame to have each element on a separate row\n",
    "    df_exploded = df.explode('elements')\n",
    "\n",
    "    # Count the frequency of each element\n",
    "    element_counts = df_exploded['elements'].value_counts()\n",
    "\n",
    "    # Select the top 30 elements\n",
    "    top_30_elements = element_counts.head(30)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_30_elements.plot(kind='bar')\n",
    "    plt.title('Top 30 Frequent Elements Distribution')\n",
    "    plt.xlabel('Element')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    return \"Successfully plotted the required diagram.\"\n",
    "\n",
    "# pandas_plot = StructuredTool.from_function(\n",
    "#     func=pandas_plot_function,\n",
    "#     name=\"PandasPlot\",\n",
    "#     description=\"useful for plotting the element distributions of the mineral data.\",\n",
    "#     args_schema=PandasDFInput\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "## histogram chain\n",
    "histogram_plotter_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "    You are a mineral data histogram plotter. Your team member will collect the dataset and give you the file path to work with.\n",
    "    All you need is the file path. \n",
    "    \n",
    "    The visualization tool is included.\n",
    "\n",
    "    Your response should include two keys in json, \"file_path\" and \"scratch_pad\" \\n\n",
    "    If the file path to the dataset is present in the message, return it in file_path field. The visualization tool will process the file.\n",
    "    If the file path isn't presented in the message, respond with \"file_path\": \"\", then comment it in the \"scratch_pad\": \"The dataset file path is empty, please collect the dataset first.\"\n",
    "\n",
    "    Pay attention to the error message if presents, revise your response accordingly.\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Messages : {messages} \\n\n",
    "    Errors: {errors} \\n\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"messages\", \"errors\"],\n",
    ")\n",
    "\n",
    "# llm = OllamaFunctions(model=\"llama3:8b\", format='json')\n",
    "\n",
    "# histogram_plotter_structured_llm = llm.with_structured_output(HistogramInput)\n",
    "# histogram_chain = histogram_plotter_prompt | histogram_plotter_structured_llm\n",
    "\n",
    "histogram_plotter_llm_with_tools = llm.bind_tools([HistogramInput])\n",
    "histogram_chain = histogram_plotter_prompt | histogram_plotter_llm_with_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogram test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "\n",
    "# messages = \"\"\"User\n",
    "# plot the histogram of the elements distribution of the ima-approved mineral species with hardness between 3-5, in Hexagonal crystal system, must have Neodymium, but without sulfur\"\"\"\n",
    "# messages = 'I want the datasets of iron minerals but without oxygen, the dataset has been saved in content/mindat_data/geomaterials_data.json'\n",
    "messages = 'I want the datasets of iron minerals but without oxygen, '\n",
    "errors = ''\n",
    "\n",
    "tolerance = 10\n",
    "for t in range(tolerance):\n",
    "    print(t)\n",
    "    try:\n",
    "        result = histogram_chain.invoke({\"messages\": messages, 'errors': errors})\n",
    "        break\n",
    "    except ValueError as e:\n",
    "        errors = str(e)\n",
    "        print(e)\n",
    "    \n",
    "print(result)\n",
    "print(type(result))\n",
    "\n",
    "# histogram_plot_function(result.tool_calls[0]['args']['file_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display, HTML, Image, IFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import webbrowser\n",
    "\n",
    "class NetworkVizInput(BaseModel):\n",
    "    file_path: str = Field(description=\"Should be a file path of json data, leave empty if not given.\")\n",
    "    scratch_pad: str = Field(description=\"Should be your comment, e.g., the file path is not given; the process works well, etc.\")\n",
    "\n",
    "def network_plot_function(file_path: str, top_n=50, display_method='new_window'):\n",
    "    # 定义颜色映射\n",
    "    color_map = {\n",
    "        1: 'red', 2: 'orange', 3: 'yellow', 4: 'green', 5: 'blue',\n",
    "        6: 'indigo', 7: 'violet', 8: 'purple', 9: 'brown', 10: 'grey', 11: 'black'\n",
    "    }\n",
    "\n",
    "    # 定义 Strunz 分类的图例\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"position: absolute; bottom: 50px; left: 10px; background-color: white; padding: 10px; border: 1px solid black; z-index: 9999;\">\n",
    "        <b>Strunz Classification - Primary Groups</b><br>\n",
    "        1. <span style=\"color: red;\">ELEMENTS</span><br>\n",
    "        2. <span style=\"color: orange;\">SULFIDES and SULFOSALTS</span><br>\n",
    "        3. <span style=\"color: yellow;\">HALIDES</span><br>\n",
    "        4. <span style=\"color: green;\">OXIDES</span><br>\n",
    "        5. <span style=\"color: blue;\">CARBONATES</span><br>\n",
    "        6. <span style=\"color: indigo;\">BORATES</span><br>\n",
    "        7. <span style=\"color: violet;\">SULFATES</span><br>\n",
    "        8. <span style=\"color: purple;\">PHOSPHATES, ARSENATES, VANADATES</span><br>\n",
    "        9. <span style=\"color: brown;\">SILICATES</span><br>\n",
    "        10. <span style=\"color: grey;\">ORGANIC COMPOUNDS</span><br>\n",
    "        11. <span style=\"color: black;\">Other</span><br>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    # 加载 JSON 数据\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 过滤数据以仅包括前 n 个矿物\n",
    "    filtered_data = data[\"results\"][:top_n]\n",
    "\n",
    "    # 创建图\n",
    "    G = nx.Graph()\n",
    "\n",
    "    try:\n",
    "        # 提取并添加节点到图中\n",
    "        mineral_locality_map = {}\n",
    "        for mineral in filtered_data:\n",
    "            mineral_id = mineral[\"id\"]\n",
    "            mineral_name = mineral[\"name\"]\n",
    "            localities = mineral[\"locality\"]\n",
    "            strunz_value = mineral.get(\"strunz10ed1\", 11)\n",
    "\n",
    "            # 确保 strunz_value 是有效的整数\n",
    "            try:\n",
    "                strunz_value = int(strunz_value)\n",
    "            except (ValueError, TypeError):\n",
    "                strunz_value = 11\n",
    "\n",
    "            color = color_map.get(int(strunz_value), 'black')\n",
    "\n",
    "            # 计算节点大小\n",
    "            node_size = 20 + math.log1p(len(localities)) * 10\n",
    "\n",
    "            # 添加矿物节点\n",
    "            G.add_node(mineral_id, label=mineral_name, color=color, size=node_size, font_size=20)\n",
    "\n",
    "            for locality in localities:\n",
    "                if locality not in mineral_locality_map:\n",
    "                    mineral_locality_map[locality] = set()\n",
    "                mineral_locality_map[locality].add(mineral_id)\n",
    "    except KeyError as e:\n",
    "        error_message = str(e) + \"\\n'expand':'locality' in geocollector data query is necessary for network visualization\"\n",
    "        return error_message\n",
    "\n",
    "    # 添加边\n",
    "    for locality, minerals in mineral_locality_map.items():\n",
    "        minerals = list(minerals)\n",
    "        for i in range(len(minerals)):\n",
    "            for j in range(i + 1, len(minerals)):\n",
    "                G.add_edge(minerals[i], minerals[j], color='grey')\n",
    "\n",
    "    # 创建 PyVis 网络\n",
    "    net = Network(notebook=True, height=\"750px\", width=\"100%\", cdn_resources='in_line')\n",
    "    net.repulsion(node_distance=400, central_gravity=0.1, spring_length=200, spring_strength=0.05, damping=0.09)\n",
    "    net.from_nx(G)\n",
    "\n",
    "    for node in net.nodes:\n",
    "        node[\"font\"] = {\"size\": node.get(\"size\", 20)}\n",
    "\n",
    "    # 保存网络图为 HTML 文件\n",
    "    output_file_path = \"minerals_network.html\"\n",
    "    net.save_graph(output_file_path)\n",
    "\n",
    "    # 插入图例到 HTML 内容\n",
    "    with open(output_file_path, 'r') as f:\n",
    "        html_content = f.read()\n",
    "    insertion_point = html_content.find('<body>') + len('<body>')\n",
    "    html_content_with_legend = html_content[:insertion_point] + legend_html + html_content[insertion_point:]\n",
    "\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        f.write(html_content_with_legend)\n",
    "\n",
    "    if display_method == 'html':\n",
    "        # 使用 HTML 显示（适用于支持的环境）\n",
    "        display(HTML(html_content_with_legend))\n",
    "    elif display_method == 'static':\n",
    "        # 使用 Matplotlib 创建静态图像\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pos = nx.spring_layout(G)\n",
    "        nx.draw(G, pos, node_color=[G.nodes[node]['color'] for node in G.nodes()], \n",
    "                node_size=[G.nodes[node]['size'] * 10 for node in G.nodes()], \n",
    "                with_labels=True, font_size=8)\n",
    "        plt.title(\"Mineral Network\")\n",
    "        plt.savefig(\"minerals_network.png\")\n",
    "        display(Image(filename=\"minerals_network.png\"))\n",
    "    elif display_method == 'file':\n",
    "        # 仅保存文件，不尝试显示\n",
    "        print(f\"Network graph saved as {output_file_path}\")\n",
    "        print(\"Please open this file in a web browser to view the interactive network.\")\n",
    "    elif display_method == 'ipython':\n",
    "        # 使用 IPython 的 IFrame 显示\n",
    "        display(IFrame(src=output_file_path, width='100%', height='600px'))\n",
    "    elif display_method == 'new_window':\n",
    "        # 在新窗口中打开 HTML 文件\n",
    "        full_path = os.path.abspath(output_file_path)\n",
    "        webbrowser.open('file://' + full_path, new=2)\n",
    "        print(f\"Opening network graph in a new window: {full_path}\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid display_method. Choose 'html', 'static', 'file', 'ipython', or 'new_window'.\")\n",
    "\n",
    "    return \"Successfully created the network plot with the specified display method.\"\n",
    "\n",
    "# network_plot = StructuredTool.from_function(\n",
    "#     func=network_plot_function,\n",
    "#     name=\"NetworkPlot\",\n",
    "#     description=\"useful for plotting the mineral data in network diagram.\",\n",
    "#     args_schema=NetworkVizInput\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## network chain\n",
    "network_plotter_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "    You are a mineral data network plotter. Your team member will collect the dataset and give you the file path to work with.\n",
    "    All you need is the file path. \n",
    "    \n",
    "    The visualization tool is included.\n",
    "\n",
    "    If the file path to the dataset is present in the message, return with the file path. The visualization tool will process the file.\n",
    "    The file path can be in windows or macOS style.\n",
    "    If you didn't find the file path attached in the message, comment it in the scratch_pad field.\n",
    "\n",
    "    Pay attention to the error message if presents, revise your response accordingly.\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Messages : {messages} \\n\n",
    "    Errors: {errors}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"messages\"],\n",
    ")\n",
    "\n",
    "# llm = OllamaFunctions(model=\"llama3:8b\", format='json')\n",
    "\n",
    "# collector_structured_llm = llm.with_structured_output(MindatCollectorInput)\n",
    "network_plotter_structured_llm = llm.with_structured_output(NetworkVizInput)\n",
    "network_chain = network_plotter_prompt | network_plotter_structured_llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### network test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "\n",
    "# messages = \"\"\"User\n",
    "# plot the histogram of the elements distribution of the ima-approved mineral species with hardness between 3-5, in Hexagonal crystal system, must have Neodymium, but without sulfur\"\"\"\n",
    "\n",
    "messages = \"please plot the mineral data for Norway, file_path: './mindat_data/geomaterial_data.json'\"\n",
    "errors = ''\n",
    "\n",
    "tolerance = 10\n",
    "for t in range(tolerance):\n",
    "    print(t)\n",
    "    try:\n",
    "        result = network_chain.invoke({\"messages\": messages, 'errors': errors})\n",
    "        break\n",
    "    except ValueError as e:\n",
    "        errors = str(e)\n",
    "        print(e)\n",
    "    \n",
    "print(result)\n",
    "print(type(result))\n",
    "print(result.file_path)\n",
    "print(type(result.file_path))\n",
    "network_plot_function(result.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from IPython.display import display, IFrame\n",
    "\n",
    "class HeatmapVizInput(BaseModel):\n",
    "    file_path: str = Field(description=\"Should be a file path of json data for the tool to load and plot heatmap visualizations\")\n",
    "\n",
    "def heatmap_plot_function(file_path: str, visualization_selection='heatmap'):\n",
    "    # Initialize sums and counters\n",
    "    lat_sum = 0\n",
    "    lon_sum = 0\n",
    "    count = 0\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Sum up all latitudes and longitudes\n",
    "    for item in data['results']:\n",
    "        lat = item['latitude']\n",
    "        lon = item['longitude']\n",
    "        # Filter out the (0,0) coordinate and other potentially erroneous coordinates\n",
    "        if lat != 0.0 and lon != 0.0:\n",
    "            lat_sum += lat\n",
    "            lon_sum += lon\n",
    "            count += 1\n",
    "\n",
    "    # Calculate the average latitude and longitude (the centroid)\n",
    "    if count > 0:\n",
    "        center_lat = lat_sum / count\n",
    "        center_lon = lon_sum / count\n",
    "    else:\n",
    "        center_lat, center_lon = 38, 77  # Default to Washington, D.C. if no valid data points\n",
    "\n",
    "    # Create a map centered around the calculated centroid\n",
    "    map = folium.Map(location=[center_lat, center_lon], zoom_start=6)\n",
    "\n",
    "    if \"pop up\" == visualization_selection:\n",
    "        # Add markers for each location in the JSON data\n",
    "        for item in data['results']:\n",
    "            lat = item['latitude']\n",
    "            lon = item['longitude']\n",
    "            # Filter out the (0,0) coordinate\n",
    "            id = item.get('id')\n",
    "            # print(type(id))\n",
    "            txt = item.get('txt', 'No txt provided')  # Default if no description is provided\n",
    "            url = f'https://www.mindat.org/loc-{id}.html'\n",
    "            # popup_info = f\"<strong>{id}</strong><br>{txt}\"\n",
    "            popup_info = folium.Popup(f\"<div style='width:200px; font-size:16px;'><strong>ID:</strong> {id}<br><strong>Description:</strong> {txt}<br><strong>URL:</strong> <a href='{url}' target='_blank'>{url}</a></div>\",\n",
    "                                max_width=265)\n",
    "            if lat != 0.0 or lon != 0.0:\n",
    "                folium.Marker(\n",
    "                    location=[lat, lon],\n",
    "                    popup=popup_info,\n",
    "                    icon=folium.Icon(color='blue', icon='info-sign')\n",
    "                ).add_to(map)\n",
    "    elif \"heatmap\" == visualization_selection:\n",
    "        # Add markers for each location in the JSON data\n",
    "        for item in data['results']:\n",
    "            lat = item['latitude']\n",
    "            lon = item['longitude']\n",
    "            # Filter out the (0,0) coordinate\n",
    "\n",
    "        # Add a heat map layer to the map\n",
    "        heat_map_data = [\n",
    "            (item['latitude'], item['longitude']) for item in data['results']\n",
    "            if item['latitude'] != 0.0 and item['longitude'] != 0.0\n",
    "        ]\n",
    "\n",
    "        HeatMap(heat_map_data).add_to(map)\n",
    "    else:\n",
    "        raise ValueError(\"Please select a visualization approach!\")\n",
    "\n",
    "    # Save the map as HTML file\n",
    "    map_html = map._repr_html_()\n",
    "\n",
    "    # Display the map in the notebook\n",
    "    display(HTML(map_html))\n",
    "    return \"Successfully plotted the required diagram.\"\n",
    "\n",
    "\n",
    "heatmap_plot = StructuredTool.from_function(\n",
    "    func=heatmap_plot_function,\n",
    "    name=\"HeatmapPlot\",\n",
    "    description=\"useful for plotting the mineral locality data in heatmap diagram.\",\n",
    "    args_schema=HeatmapVizInput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmap chain\n",
    "heatmap_plotter_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "    You are a mineral locality heatmap plotter. Your team member will collect the dataset and give you the file path to work with.\n",
    "    All you need is the file path. \n",
    "    \n",
    "    The visualization tool is included.\n",
    "\n",
    "    If the file path to the dataset is present in the message, return with the file path. The visualization tool will process the file.\n",
    "    The file path can be in windows or macOS style.\n",
    "    If you didn't find the file path attached in the message, comment it in the scratch_pad field.\n",
    "\n",
    "    Pay attention to the error message if presents, revise your response accordingly.\n",
    "\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Messages : {messages} \\n\n",
    "    Errors: {errors}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"messages\"],\n",
    ")\n",
    "\n",
    "# llm = OllamaFunctions(model=\"llama3:8b\", format='json')\n",
    "\n",
    "# collector_structured_llm = llm.with_structured_output(MindatCollectorInput)\n",
    "heatmap_plotter_structured_llm = llm.with_structured_output(HeatmapVizInput)\n",
    "heatmap_chain = heatmap_plotter_prompt | heatmap_plotter_structured_llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "\n",
    "# messages = \"\"\"User\n",
    "# plot the histogram of the elements distribution of the ima-approved mineral species with hardness between 3-5, in Hexagonal crystal system, must have Neodymium, but without sulfur\"\"\"\n",
    "\n",
    "messages = \"please plot the mineral data for Norway, file_path: './mindat_data/locality_data.json'\"\n",
    "errors = ''\n",
    "\n",
    "tolerance = 10\n",
    "for t in range(tolerance):\n",
    "    print(t)\n",
    "    try:\n",
    "        result = heatmap_chain.invoke({\"messages\": messages, 'errors': errors})\n",
    "        break\n",
    "    except ValueError as e:\n",
    "        errors = str(e)\n",
    "        print(e)\n",
    "    \n",
    "print(result)\n",
    "print(type(result))\n",
    "print(result.file_path)\n",
    "print(type(result.file_path))\n",
    "heatmap_plot_function(result.file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "# class AgentState(TypedDict):\n",
    "#     # The annotation tells the graph that new messages will always\n",
    "#     # be added to the current states\n",
    "#     messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "#     # The 'next' field indicates where to route to next\n",
    "#     next: str\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: list\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "    # Step count\n",
    "    step: int\n",
    "    # Plotter file history\n",
    "    plotter_file_history: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# from langchain_core.messages import BaseMessage, HumanMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "#     # Each worker node will be given a name and some tools.\n",
    "#     prompt = ChatPromptTemplate.from_messages(\n",
    "#         [\n",
    "#             (\n",
    "#                 \"system\",\n",
    "#                 system_prompt,\n",
    "#             ),\n",
    "#             MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#             MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#         ]\n",
    "#     )\n",
    "#     agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "#     executor = AgentExecutor(agent=agent, tools=tools)\n",
    "#     return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisor Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error --no-raise-exception\n",
    "\n",
    "def supervisor_node(state):\n",
    "    \"\"\"\n",
    "    Route user request to agent team members.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    print('====in supervisor node====')\n",
    "\n",
    "    # state message initialization\n",
    "    if not isinstance(state['messages'], list):\n",
    "        state['messages'] = [state['messages']]\n",
    "    # state step initialization\n",
    "    if 1 == len(state['messages']):\n",
    "        state['messages'][0] = \"User: \" + state['messages'][0]\n",
    "        state['step'] = 0\n",
    "        \n",
    "    # print out the message logs\n",
    "    messages = state['messages']\n",
    "    for msg in messages:\n",
    "        print(msg)\n",
    "\n",
    "    errors = ''\n",
    "\n",
    "    retry_tolerance = 10\n",
    "    \n",
    "    for retry_count in range(retry_tolerance):\n",
    "        print(f\"Retrying({retry_count}/{retry_tolerance})\", end='\\r')\n",
    "        try:\n",
    "            result = supervisor_chain.invoke({\n",
    "                \"members\": members, \n",
    "                \"messages\": str(messages), \n",
    "                \"options\":options, \n",
    "                \"errors\": errors,\n",
    "            })\n",
    "            # result_next = result.tool_calls[0]['args']['next']\n",
    "            # if result_next in options:\n",
    "            #     break\n",
    "            # else:\n",
    "            #     errors = f\"{result_next} not in {options}, please try again.\"\n",
    "            # print(\"supervisor output: \", result.tool_calls[0]['args'])\n",
    "            \n",
    "            print(\"supervisor result: \", result)\n",
    "            # raw_result = result.tool_calls[0]['args']\n",
    "            # raw_result = result.next\n",
    "\n",
    "            # 解析 JSON 字符串为字典\n",
    "            raw_result = str(result.content)\n",
    "            # print('rawresult:', raw_result)\n",
    "            result_next = next_parser(raw_result)\n",
    "            # print('resultnext:', result_next)\n",
    "            # result_next = str(result.tool_calls[0]['args']['next'])\n",
    "            if result_next:\n",
    "                break\n",
    "            else:\n",
    "                jargon_errors = f\"{raw_result} not in {options}, please try again.\"\n",
    "                errors = jargon_errors\n",
    "                print(\"Jargon errors: \", jargon_errors)\n",
    "\n",
    "        except (ValueError, KeyError, IndexError, AttributeError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            # print(\"!!error type: \", error_type)\n",
    "            if \"ValueError\" == str(error_type) or \"AttributeError\" == str(error_type):\n",
    "                print(str(e))\n",
    "                try:\n",
    "                    result_dict = parse_required_keys_from_llm_response(str(e))\n",
    "                    result_next = next_parser(result_dict)\n",
    "                    if result_next:\n",
    "                        break\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            # if \"AttributeError\" == str(error_type): \n",
    "            #     result_next = next_parser(str(result))\n",
    "            #     if result_next:\n",
    "            #         break\n",
    "\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "    \n",
    "    \n",
    "    updated_message = state['messages'] + [\"Step {step}, Supervisor node: {result_next}\".format(step=state['step'], result_next=result_next)]\n",
    "\n",
    "    return {\n",
    "        \"messages\": updated_message,\n",
    "        \"next\": result_next,\n",
    "        \"step\": state['step'] + 1\n",
    "    }\n",
    "    \n",
    "\n",
    "def next_parser(JARGON: str):\n",
    "    jargon_str = JARGON.upper()\n",
    "    # 记录每个匹配选项在字符串中的位置\n",
    "    found_positions = {}\n",
    "    for option in options:\n",
    "        if option in jargon_str:\n",
    "            found_positions[option] = jargon_str.index(option)\n",
    "    \n",
    "    # 如果找到了匹配项，返回位置最靠前的那个\n",
    "    if found_positions:\n",
    "        return min(found_positions.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_required_keys_from_llm_response(llm_response):\n",
    "    # 定义所需的键\n",
    "    required_keys = [\"next\", \"supervisor_reason\"]\n",
    "    extracted_data = {}\n",
    "\n",
    "    # 使用正则表达式匹配所有键值对，匹配键和值为双引号或单引号包裹的内容\n",
    "    for key in required_keys:\n",
    "        pattern = rf'[\"]({key})[\"](?:\\s*:\\s*)[\"](.*?)[\"]'\n",
    "        match = re.search(pattern, llm_response, re.DOTALL)\n",
    "        if match:\n",
    "            extracted_data[match.group(1)] = match.group(2)\n",
    "\n",
    "    # 检查是否所有键都被提取\n",
    "    if len(extracted_data) == len(required_keys):\n",
    "        return json.loads(json.dumps(extracted_data))\n",
    "    else:\n",
    "        missing_keys = set(required_keys) - set(extracted_data.keys())\n",
    "        raise ValueError(f\"Missing keys in LLM response: {missing_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supervisor node test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "test_state = AgentState(messages = ['This is a testflight, return FINISH.'], next = None, step=0, plotter_file_history = None)\n",
    "# test_state = AgentState(messages = ['i want you to download dataset for carbon and oxygen mineral but without Magnesium. \\nStep 0, Supervisor node: COLLECTOR, \\nStep 1, Collector node: The Collector node successfully saved the dataset to /Users/blc/pyspace/Git_Mindat/mindatxllm/content/mindat_data/geomaterials_data.json'], next = None, step=0, plotter_file_history = None)\n",
    "print(supervisor_node(test_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo Collector Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_collector_node(state):\n",
    "    print(\"====in geo collector node====\")\n",
    "    messages = state['messages']\n",
    "    errors = ''\n",
    "\n",
    "    retry_tolerance = 10\n",
    "    for retry_count in range(retry_tolerance):\n",
    "        print(f\"Retrying({retry_count}/{retry_tolerance})\", end='\\r')\n",
    "        try:\n",
    "            result = geo_collector_chain.invoke({\n",
    "                    \"messages\": str(messages), \n",
    "                    \"errors\": errors, \n",
    "                    'example_query1': example_query1,\n",
    "                    'example_query2': example_query2,\n",
    "                    'example_query3': example_query3,\n",
    "                })\n",
    "            result_querydict = result.tool_calls[0]['args']\n",
    "            collector_result = geomaterial_collector_function(result_querydict)\n",
    "            if collector_result:\n",
    "                break\n",
    "            else:\n",
    "                errors = \"The query has no result, please read the user request and try again.\"\n",
    "\n",
    "        except (ValueError, IndexError, KeyError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "\n",
    "    # print(result)\n",
    "    openmindat_results = str(collector_result)\n",
    "\n",
    "    updated_messages = state['messages'] + [\"Step {step}, Collector node: {openmindat_results}\".format(step=state['step'], openmindat_results=openmindat_results)]\n",
    "    return {\n",
    "                \"messages\": updated_messages,\n",
    "                \"step\": state['step'] + 1\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loc Collector Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_collector_node(state):\n",
    "    print(\"====in loc collector node====\")\n",
    "    messages = state['messages']\n",
    "    errors = ''\n",
    "\n",
    "    retry_tolerance = 10\n",
    "    for retry_count in range(retry_tolerance):\n",
    "        print(f\"Retrying({retry_count}/{retry_tolerance})\", end='\\r')\n",
    "        try:\n",
    "            result = loc_collector_chain.invoke({\n",
    "                    \"messages\": str(messages), \n",
    "                    \"errors\": errors, \n",
    "                    'example_loc_query1': example_loc_query1,\n",
    "                    'example_loc_query2': example_loc_query2,\n",
    "                    'example_loc_query3': example_loc_query3,\n",
    "                })\n",
    "            result_querydict = result.tool_calls[0]['args']\n",
    "            collector_result = locality_collector_function(result_querydict)\n",
    "            if collector_result:\n",
    "                break\n",
    "            else:\n",
    "                errors = \"The query has no result, please read the user request and try again.\"\n",
    "\n",
    "        except (ValueError, IndexError, KeyError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "\n",
    "    # print(result)\n",
    "    openmindat_results = str(collector_result)\n",
    "\n",
    "    updated_messages = state['messages'] + [\"Step {step}, Collector node: {openmindat_results}\".format(step=state['step'], openmindat_results=openmindat_results)]\n",
    "    return {\n",
    "                \"messages\": updated_messages,\n",
    "                \"step\": state['step'] + 1\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "def histogram_plotter_node(state):\n",
    "    print(\"====in histogram plotter node====\")\n",
    "    messages = state['messages']\n",
    "    errors = ''\n",
    "\n",
    "    retry_tolerance = 10\n",
    "    for retry_count in range(retry_tolerance):\n",
    "        print(f\"Retrying({retry_count}/{retry_tolerance})\", end='\\r')\n",
    "        try:\n",
    "            result = histogram_chain.invoke({\"messages\": str(messages), \"errors\": errors})\n",
    "            result_path = result.tool_calls[0]['args']['file_path']\n",
    "            break\n",
    "\n",
    "        except (ValueError, KeyError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "\n",
    "    path_obj = Path(result_path)\n",
    "\n",
    "    updated_plot_history = ''\n",
    "\n",
    "    if str(path_obj) == state['plotter_file_history']:\n",
    "        redundant_message = \"I have already finished the requested histogram plotting. If you have another new request, please let me know.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, Histogram plotter node: {redundant_message}\".format(step=state['step'], redundant_message=redundant_message)]\n",
    "        updated_plot_history = state['plotter_file_history']\n",
    "        \n",
    "    elif path_obj.exists() and Path('.') != path_obj:\n",
    "        histogram_plot_function(path_obj)\n",
    "        successful_message = \"I have successfully finished the histogram request.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, Histogram plotter node: {successful_message}\".format(step=state['step'], successful_message=successful_message)]\n",
    "        updated_plot_history = str(path_obj)\n",
    "\n",
    "        print(\"!!!printing test: \\nstr(path_obj):\", str(path_obj), \"state['plotter_file_history']:\", state['plotter_file_history'])\n",
    "    else:\n",
    "        file_missing_message = \"The file path was not a valid path, please collect the dataset first.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, Histogram plotter node: {file_missing_message}\".format(step=state['step'], file_missing_message=file_missing_message)]\n",
    "\n",
    "    return {\n",
    "                \"messages\": updated_messages,\n",
    "                \"step\": state['step'] + 1,\n",
    "                \"plotter_file_history\": updated_plot_history\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Plotter Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_plotter_node(state):\n",
    "    print(\"====in network plotter node====\")\n",
    "    messages = state['messages']\n",
    "    errors = ''\n",
    "\n",
    "    retry_tolerance = 10\n",
    "    for retry_count in range(retry_tolerance):\n",
    "        print(f\"Retrying({retry_count}/{retry_tolerance})\", end='\\r')\n",
    "        try:\n",
    "            result = network_chain.invoke({\"messages\": str(messages), \"errors\": errors})\n",
    "            # result_path = result.tool_calls[0]['args']['file_path']\n",
    "            result_path = result.file_path\n",
    "            break\n",
    "\n",
    "        except (ValueError, KeyError, AttributeError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "\n",
    "    path_obj = Path(result_path)\n",
    "\n",
    "    updated_plot_history = ''\n",
    "\n",
    "    if str(path_obj) == state.get('plotter_file_history'):\n",
    "        redundant_message = \"I have already finished the requested Network plotting. If you have another new request, please let me know.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, Network plotter node: {redundant_message}\".format(step=state['step'], redundant_message=redundant_message)]\n",
    "        updated_plot_history = state['plotter_file_history']\n",
    "        \n",
    "    elif path_obj.exists() and Path('.') != path_obj:\n",
    "        network_plot_function(path_obj)\n",
    "        successful_message = \"I have successfully finished the Network request.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, Network plotter node: {successful_message}\".format(step=state['step'], successful_message=successful_message)]\n",
    "        updated_plot_history = str(path_obj)\n",
    "\n",
    "        # print(\"!!!printing test: \\nstr(path_obj):\", str(path_obj), \"state['plotter_file_history']:\", state.get('plotter_file_history'))\n",
    "    else:\n",
    "        file_missing_message = \"The file path was not a valid path, please collect the dataset first.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, Network plotter node: {file_missing_message}\".format(step=state['step'], file_missing_message=file_missing_message)]\n",
    "\n",
    "    return {\n",
    "                \"messages\": updated_messages,\n",
    "                \"step\": state['step'] + 1,\n",
    "                \"plotter_file_history\": updated_plot_history\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap Plotter Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_plotter_node(state):\n",
    "    print(\"====in heatmap plotter node====\")\n",
    "    messages = state['messages']\n",
    "    errors = ''\n",
    "\n",
    "    retry_tolerance = 10\n",
    "    for retry_count in range(retry_tolerance):\n",
    "        print(f\"Retrying({retry_count}/{retry_tolerance})\", end='\\r')\n",
    "        try:\n",
    "            result = heatmap_chain.invoke({\"messages\": str(messages), \"errors\": errors})\n",
    "            # result_path = result.tool_calls[0]['args']['file_path']\n",
    "            result_path = result.file_path\n",
    "            break\n",
    "\n",
    "        except (ValueError, KeyError, AttributeError) as e:\n",
    "            error_type = type(e).__name__\n",
    "            errors = f\"{error_type}: {str(e)}\"\n",
    "            print(errors)\n",
    "\n",
    "    path_obj = Path(result_path)\n",
    "\n",
    "    updated_plot_history = ''\n",
    "\n",
    "    if str(path_obj) == state.get('plotter_file_history'):\n",
    "        redundant_message = \"I have already finished the requested heatmap plotting. If you have another new request, please let me know.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, heatmap plotter node: {redundant_message}\".format(step=state['step'], redundant_message=redundant_message)]\n",
    "        updated_plot_history = state['plotter_file_history']\n",
    "        \n",
    "    elif path_obj.exists() and Path('.') != path_obj:\n",
    "        heatmap_plot_function(path_obj)\n",
    "        successful_message = \"I have successfully finished the heatmap request.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, heatmap plotter node: {successful_message}\".format(step=state['step'], successful_message=successful_message)]\n",
    "        updated_plot_history = str(path_obj)\n",
    "\n",
    "        # print(\"!!!printing test: \\nstr(path_obj):\", str(path_obj), \"state['plotter_file_history']:\", state.get('plotter_file_history'))\n",
    "    else:\n",
    "        file_missing_message = \"The file path was not a valid path, please collect the dataset first.\"\n",
    "        updated_messages = state['messages'] + [\"Step {step}, heatmap plotter node: {file_missing_message}\".format(step=state['step'], file_missing_message=file_missing_message)]\n",
    "\n",
    "    return {\n",
    "                \"messages\": updated_messages,\n",
    "                \"step\": state['step'] + 1,\n",
    "                \"plotter_file_history\": updated_plot_history\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_agents(state):\n",
    "    \"\"\"\n",
    "    Route user request to agent team members.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print('====route to team members====')\n",
    "    next = state['next']\n",
    "\n",
    "    # state['messages'] = list(state['messages']) + [\"Supervisor node: 'next': {next}\"]\n",
    "    \n",
    "    return next.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16179bd70>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"supervisor_node\", supervisor_node)\n",
    "workflow.add_node(\"geo_collector_node\", geo_collector_node)\n",
    "workflow.add_node(\"loc_collector_node\", loc_collector_node)\n",
    "# workflow.add_node(\"histogram_plotter_node\", histogram_plotter_node)\n",
    "workflow.add_node(\"network_plotter_node\", network_plotter_node)\n",
    "workflow.add_node(\"heatmap_plotter_node\", heatmap_plotter_node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16179bd70>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"supervisor_node\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor_node\",\n",
    "    route_to_agents,\n",
    "    {\n",
    "        \"GEOMATERIAL_COLLECTOR\": \"geo_collector_node\",\n",
    "        \"LOCALITY_COLLECTOR\": \"loc_collector_node\",\n",
    "        # \"HISTOGRAM_PLOTTER\": \"histogram_plotter_node\",\n",
    "        \"NETWORK_PLOTTER\": \"network_plotter_node\",\n",
    "        \"HEATMAP_PLOTTER\": \"heatmap_plotter_node\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"geo_collector_node\", \"supervisor_node\")\n",
    "workflow.add_edge(\"loc_collector_node\", \"supervisor_node\")\n",
    "workflow.add_edge(\"network_plotter_node\", \"supervisor_node\")\n",
    "workflow.add_edge(\"heatmap_plotter_node\", \"supervisor_node\")\n",
    "# workflow.add_edge(\"histogram_plotter_node\", \"supervisor_node\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "compiled_graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(compiled_graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====in supervisor node====\n",
      "User: i want you to plot network visualization for carbon and iron mineral but without Magnesium\n",
      "supervisor result:  content='{\"nextStep\": \"GEOMATERIAL_COLLECTOR\", \"supervisor_reason\": \"The request is for network visualization, which requires data collection first.\"}' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-10-27T04:26:11.157162Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 3627656042, 'load_duration': 31594125, 'prompt_eval_count': 509, 'prompt_eval_duration': 2167115000, 'eval_count': 33, 'eval_duration': 1421383000} id='run-301efd7b-bfc8-43b6-9e7a-745afbaff280-0' usage_metadata={'input_tokens': 509, 'output_tokens': 33, 'total_tokens': 542}\n",
      "====route to team members====\n",
      "'Finished running: supervisor_node'\n",
      "====in geo collector node====\n",
      "====in geomaterial collecting function====\n",
      "{'elements_exc': 'Mg', 'elements_inc': 'C,Fe', 'expand': 'locality', 'ima': True, 'page_size': 200}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc2f4c397ee48c8a692f60231ecf80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching data:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 28 entries to /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/mindat_data/geomaterial_data.json\n",
      "'Finished running: geo_collector_node'\n",
      "====in supervisor node====\n",
      "User: i want you to plot network visualization for carbon and iron mineral but without Magnesium\n",
      "Step 0, Supervisor node: GEOMATERIAL_COLLECTOR\n",
      "Step 1, Collector node: The Geomaterial Collector node has successfully saved the dataset to /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/mindat_data/geomaterial_data.json\n",
      "supervisor result:  content='{\"nextStep\": \"NETWORK_PLOTTER\", \"supervisor_reason\": \"Data collection is complete, and the user requested network visualization for specific minerals.\"}' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-10-27T04:26:31.397519Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 8073096375, 'load_duration': 3387487125, 'prompt_eval_count': 574, 'prompt_eval_duration': 3008609000, 'eval_count': 33, 'eval_duration': 1504038000} id='run-cbf3ac3e-84b6-40f1-b027-bf1af3a1a3cf-0' usage_metadata={'input_tokens': 574, 'output_tokens': 33, 'total_tokens': 607}\n",
      "====route to team members====\n",
      "'Finished running: supervisor_node'\n",
      "====in network plotter node====\n",
      "Opening network graph in a new window: /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/minerals_network.html\n",
      "'Finished running: network_plotter_node'\n",
      "====in supervisor node====\n",
      "User: i want you to plot network visualization for carbon and iron mineral but without Magnesium\n",
      "Step 0, Supervisor node: GEOMATERIAL_COLLECTOR\n",
      "Step 1, Collector node: The Geomaterial Collector node has successfully saved the dataset to /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/mindat_data/geomaterial_data.json\n",
      "Step 2, Supervisor node: NETWORK_PLOTTER\n",
      "Step 3, Network plotter node: I have successfully finished the Network request.\n",
      "supervisor result:  content='{\"nextStep\": \"FINISH\", \"supervisor_reason\": \"The network visualization request has been successfully fulfilled.\"}' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-10-27T04:26:49.245057Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 8644128250, 'load_duration': 4361591125, 'prompt_eval_count': 605, 'prompt_eval_duration': 3187939000, 'eval_count': 25, 'eval_duration': 1083613000} id='run-55316ae1-564e-4a0d-b4d1-bfb42df73f85-0' usage_metadata={'input_tokens': 605, 'output_tokens': 25, 'total_tokens': 630}\n",
      "====route to team members====\n",
      "'Finished running: supervisor_node'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = \"i want you to plot network visualization for carbon and iron mineral but without Magnesium\"\n",
    "# inputs = \"I want to know the spatial distribution of ophiolite.\"\n",
    "# inputs = \"i want you to plot histogram visualization for carbon and oxygen mineral but without Magnesium\"\n",
    "# inputs = \"i want to order a burger\"\n",
    "# inputs = \"trsghreiobje\"\n",
    "# run the agent\n",
    "\n",
    "message_dict = {\"messages\": inputs}\n",
    "\n",
    "# inputs = {\"messages\": \"this is a testflight, please respond with Finish\"}\n",
    "for output in compiled_graph.stream(message_dict):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====in supervisor node====\n",
      "User: I want to plot the mineral locality data for thailand in heatmap\n",
      "supervisor result:  content='{\"nextStep\": \"LOCALITY_COLLECTOR\", \"supervisor_reason\": \"User requested locality data for heatmap visualization, initiating collection of relevant information.\"}' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-10-27T04:05:58.004075Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1604064083, 'load_duration': 34427791, 'prompt_eval_count': 503, 'prompt_eval_duration': 188925000, 'eval_count': 33, 'eval_duration': 1375532000} id='run-bb79b57f-3e42-4f6b-b382-866b4d067baa-0' usage_metadata={'input_tokens': 503, 'output_tokens': 33, 'total_tokens': 536}\n",
      "====route to team members====\n",
      "'Finished running: supervisor_node'\n",
      "====in loc collector node====\n",
      "====in locality collecting function====\n",
      "{'country': 'Thailand'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888955d0e9514fe8806bd8f360770388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 254 entries to /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/mindat_data/locality_data.json\n",
      "'Finished running: loc_collector_node'\n",
      "====in supervisor node====\n",
      "User: I want to plot the mineral locality data for thailand in heatmap\n",
      "Step 0, Supervisor node: LOCALITY_COLLECTOR\n",
      "Step 1, Collector node: The Locality Colector node has successfully saved the dataset to /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/mindat_data/locality_data.json\n",
      "supervisor result:  content='{\\n  \"next\\': \\'HEATMAP_PLOTTER\\':} \\\\n FINISH \\\\n)<|begin_of_text|>' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-10-27T04:06:11.714961Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7063302875, 'load_duration': 3118891083, 'prompt_eval_count': 566, 'prompt_eval_duration': 2867813000, 'eval_count': 23, 'eval_duration': 1067081000} id='run-ee95cb63-7814-4ed2-bea2-cc42f0396682-0' usage_metadata={'input_tokens': 566, 'output_tokens': 23, 'total_tokens': 589}\n",
      "====route to team members====\n",
      "'Finished running: supervisor_node'\n",
      "====in heatmap plotter node====\n",
      "Retrying(0/10)\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_211e6b5d694cd5d288c03c3e09064404 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium@main/folium/templates/leaflet_heat.min.js&quot;&gt;&lt;/script&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_211e6b5d694cd5d288c03c3e09064404&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_211e6b5d694cd5d288c03c3e09064404 = L.map(\n",
       "                &quot;map_211e6b5d694cd5d288c03c3e09064404&quot;,\n",
       "                {\n",
       "                    center: [13.943196185127741, 100.31619895869059],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 6,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_fd96036ebd56dde745577b1834eaeee7 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_fd96036ebd56dde745577b1834eaeee7.addTo(map_211e6b5d694cd5d288c03c3e09064404);\n",
       "        \n",
       "    \n",
       "            var heat_map_d9f736685cbbe23db67fffec7c8b3ae4 = L.heatLayer(\n",
       "                [[14.3247222222, 99.5158333333], [12.5833333333, 102.056111111], [16.2891666667, 100.65], [17.700813, 101.764044], [18.1566666667, 97.9347222222], [14.9666666667, 102.116666667], [7.935, 98.35], [13.678888888889, 99.176666666667], [7.9742259318822, 99.055493164062], [11.854722222222, 99.722222222222], [12.846666666667, 99.804444444444], [16.6605555556, 98.6605555556], [19.4, 99.5666666667], [18.1333333333, 99.85], [8.5153, 99.4315], [18.75, 98.65], [6.966542, 100.531101], [17.356192978951, 101.65219289796], [8.73333333333, 99.35], [18.75, 99.6333], [17.3333333333, 101.5], [17.5, 101.666666667], [18.1166666667, 102.083333333], [8.58333333333, 98.5], [7.822632001424, 98.296582614673], [8.0574555776685, 98.283064345461], [17.8, 98.1666666667], [17.11538668424, 101.94808291893], [14.305833333333, 99.478333333333], [12.616666666667, 102.05], [12.579722222222, 102.525], [14.390277777778, 99.513055555556], [14.316666666667, 99.5], [14.205555555556, 99.447777777778], [14.131388888889, 99.399444444444], [6.2230555555556, 101.15055555556], [16.6666666667, 101.183333333], [6.2007252931256, 101.18141172485], [16.308694, 100.652607], [16.291821935517, 100.65645933151], [16.30032, 100.65293], [16.32035, 100.651813], [16.307582, 100.656019], [16.294607, 100.646277], [16.29132, 100.64187], [16.0383333333, 103.119166667], [6.257263280212, 101.16498463205], [8.262039, 99.829653], [14.670833333333, 98.383333333333], [9.73055555556, 100.014166667], [16.270332681993, 100.65140368597], [16.269903628048, 100.65847470263], [16.281191480313, 100.66731325255], [14.938538, 103.094657], [10.101983486216, 99.847203961742], [8.4331, 99.44316], [20.216666666667, 100.45], [18.25, 99.633333333333], [15.166666666667, 101.0], [14.65, 104.8], [14.642413, 104.492234], [17.303792, 102.881682], [18.321017770174, 99.704607745925], [8.7600343889514, 99.36595442988], [8.6824751808972, 99.364824540418], [8.6658404635529, 99.381537406487], [8.6244207503513, 99.388834257438], [8.6960705091709, 99.364294629639], [8.9535877753494, 99.467042036898], [9.1340942088032, 99.423732646164], [8.9422192048544, 98.986157912452], [8.9330145252655, 98.962350487755], [9.1541068399833, 99.554065676398], [9.1710215501155, 99.580578019837], [9.1194103624713, 99.727600467013], [9.023846, 99.822549], [8.6758805600261, 99.761952412131], [19.401666666667, 98.823888888889], [9.139722, 99.330556], [9.0583333333333, 99.25], [8.5908759, 98.3745717], [8.1838054305149, 98.379942566656], [15.073454305683, 102.21027677092], [12.340657, 102.469825], [17.75519547, 101.75863603], [16.297067562849, 100.47987964841], [16.377134780168, 100.75418481222], [16.34311386, 100.73166758], [16.29651, 100.64731], [16.29458, 100.65614], [16.29268, 100.65333], [16.288566438499, 100.63961157589], [16.2918, 100.6301], [16.31613, 100.64999], [16.30533, 100.65565], [16.30121, 100.64849], [16.28431, 100.64937], [16.28505, 100.63327], [16.29169, 100.65983], [16.2983736239, 100.66078109144], [16.318766308825, 100.64964088658], [16.30397, 100.65198], [16.37684, 100.77566], [16.37065, 100.76667], [16.36571, 100.76684], [16.36329, 100.76819], [16.38218, 100.76271], [16.38144, 100.75612], [16.38968, 100.75354], [16.39395, 100.76094], [16.3996, 100.75137], [16.39718, 100.75624], [16.293835678842, 100.65652805575], [19.80304373242, 99.254294020427], [18.197222222222, 99.135833333333], [9.95, 98.684166666667], [8.9227777777778, 99.809722222222], [17.033333333333, 99.154166666667], [14.492777777778, 101.77611111111]],\n",
       "                {&quot;blur&quot;: 15, &quot;maxZoom&quot;: 18, &quot;minOpacity&quot;: 0.5, &quot;radius&quot;: 25}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            heat_map_d9f736685cbbe23db67fffec7c8b3ae4.addTo(map_211e6b5d694cd5d288c03c3e09064404);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Finished running: heatmap_plotter_node'\n",
      "====in supervisor node====\n",
      "User: I want to plot the mineral locality data for thailand in heatmap\n",
      "Step 0, Supervisor node: LOCALITY_COLLECTOR\n",
      "Step 1, Collector node: The Locality Colector node has successfully saved the dataset to /Users/blc/Documents/Manuscripts/2409_OpenLLMWorkflow/Code/jupyter/mindat_data/locality_data.json\n",
      "Step 2, Supervisor node: HEATMAP_PLOTTER\n",
      "Step 3, heatmap plotter node: I have successfully finished the heatmap request.\n",
      "supervisor result:  content='{\"nextStep\": \"FINISH\"}' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-10-27T04:06:25.107457Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6489626209, 'load_duration': 3104101625, 'prompt_eval_count': 599, 'prompt_eval_duration': 3028345000, 'eval_count': 9, 'eval_duration': 349313000} id='run-29e10125-618d-48a1-a6d6-f60866f7e748-0' usage_metadata={'input_tokens': 599, 'output_tokens': 9, 'total_tokens': 608}\n",
      "====route to team members====\n",
      "'Finished running: supervisor_node'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# inputs = \"i want to plot the locality data for Norway in heatmap\"\n",
    "# inputs = 'can you plot the locality data for north Europe in heatmap.'\n",
    "inputs = 'I want to plot the mineral locality data for thailand in heatmap'\n",
    "# inputs = \"i want you to plot histogram visualization for carbon and oxygen mineral but without Magnesium\"\n",
    "# inputs = \"i want to order a burger\"\n",
    "# inputs = \"trsghreiobje\"\n",
    "# run the agent\n",
    "message_dict = {\"messages\": inputs}\n",
    "\n",
    "# inputs = {\"messages\": \"this is a testflight, please respond with Finish\"}\n",
    "for output in compiled_graph.stream(message_dict):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{ \"nextStep\": \"FINISH\" }' additional_kwargs={} response_metadata={'model': 'gene21d4/llama_3.1_instruct_8b_openmindat:latest', 'created_at': '2024-11-04T23:49:20.382581Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 13375923375, 'load_duration': 10380253500, 'prompt_eval_count': 499, 'prompt_eval_duration': 2539499000, 'eval_count': 11, 'eval_duration': 443281000} id='run-14e580a4-c713-455e-b04a-5d28e3a69f48-0' usage_metadata={'input_tokens': 499, 'output_tokens': 11, 'total_tokens': 510}\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error --no-raise-exception\n",
    "messages = 'This is a testflight, return FINISH directly'\n",
    "\n",
    "structured_llm = supervisor_llm\n",
    "supervisor_chain = supervisor_prompt | structured_llm\n",
    "\n",
    "result = supervisor_chain.invoke({\n",
    "                \"members\": members, \n",
    "                \"messages\": str(messages), \n",
    "                \"options\":options, \n",
    "                \"errors\": errors,\n",
    "            })\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a32e4fc4b04b22a1b3d9bdcaf2ca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Tasks:   0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task processing completed and saved to evaluated_tasks.json and statistics.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Initialize statistics dictionary\n",
    "statistics = {\n",
    "    \"FP\": [],  # False Positive\n",
    "    \"FN\": [],  # False Negative  \n",
    "    \"TP\": [],  # True Positive\n",
    "    \"TN\": []   # True Negative\n",
    "}\n",
    "\n",
    "# Read JSON file\n",
    "with open('test_union_1104.json', 'r') as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "# Iterate through each task and call LLM Chain\n",
    "for task in tqdm(tasks, desc=\"Processing Tasks\", total=len(tasks)):\n",
    "    # Prepare input data\n",
    "\n",
    "    messages = task[\"input\"]\n",
    "    input_data = {\n",
    "                \"members\": members, \n",
    "                \"messages\": str(messages), \n",
    "                \"options\":options, \n",
    "                \"errors\": errors,\n",
    "            }\n",
    "\n",
    "   # Call chain and capture output\n",
    "    try:\n",
    "        result = supervisor_chain.invoke(input_data)\n",
    "        evaluation_output = result.content\n",
    "\n",
    "        # Add evaluation_output to task dictionary\n",
    "        task[\"evaluation_output\"] = str(evaluation_output)\n",
    "\n",
    "        # Get next values for comparison\n",
    "        output_next = task[\"output\"].get(\"next\")\n",
    "        eval_next = next_parser(evaluation_output)\n",
    "\n",
    "       # Classification statistics and add evaluation tag\n",
    "        if eval_next == output_next:  # Predicted value matches actual value\n",
    "            if eval_next == \"FINISH\":  # Matched finish state\n",
    "                statistics[\"TN\"].append(task[\"id\"]) \n",
    "                task[\"evaluation_tag\"] = \"TN\"  # True Negative - Correctly predicted finish\n",
    "            else:  # Matched other states (continue to next step)\n",
    "                statistics[\"TP\"].append(task[\"id\"])\n",
    "                task[\"evaluation_tag\"] = \"TP\"  # True Positive - Correctly predicted next step\n",
    "        else:  # Predicted value does not match actual value\n",
    "            if eval_next == \"FINISH\":  # Model predicted finish but should continue\n",
    "                statistics[\"FN\"].append(task[\"id\"])\n",
    "                task[\"evaluation_tag\"] = \"FN\"  # False Negative - Incorrectly predicted finish\n",
    "            else:  # Model predicted wrong next step\n",
    "                statistics[\"FP\"].append(task[\"id\"])\n",
    "                task[\"evaluation_tag\"] = \"FP\"  # False Positive - Predicted wrong continue state\n",
    "\n",
    "        # Optional: Add detailed evaluation information\n",
    "        task[\"evaluation_details\"] = {\n",
    "            \"expected_next\": output_next,\n",
    "            \"predicted_next\": eval_next,\n",
    "            \"is_match\": eval_next == output_next,\n",
    "            \"tag\": task[\"evaluation_tag\"]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing task {task['id']}: {str(e)}\")\n",
    "        task[\"evaluation_tag\"] = \"ERROR\"\n",
    "        task[\"evaluation_details\"] = {\"error\": str(e)}\n",
    "\n",
    "\n",
    "\n",
    "def next_parser(JARGON: str):\n",
    "    jargon_str = str(JARGON).upper()\n",
    "\n",
    "    found_positions = {}\n",
    "    # options = ['FINISH', 'GEOMATERIAL_COLLECTOR', 'LOCALITY_COLLECTOR', 'NETWORK_PLOTTER', 'HEATMAP_PLOTTER']\n",
    "\n",
    "    for option in options:\n",
    "        if option in jargon_str:\n",
    "            found_positions[option] = jargon_str.index(option)\n",
    "    \n",
    "    # Return with the first value in the output\n",
    "    if found_positions:\n",
    "        return min(found_positions.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Save processed tasks and statistics to new JSON files  \n",
    "with open('evaluated_tasks.json', 'w') as f:\n",
    "    json.dump(tasks, f, indent=2)\n",
    "\n",
    "# Save statistics to separate statistics file\n",
    "with open('statistics.json', 'w') as f:\n",
    "    json.dump(statistics, f, indent=2)\n",
    "\n",
    "print(\"Task processing completed and saved to evaluated_tasks.json and statistics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP (False Positive): 21\n",
      "FN (False Negative): 10\n",
      "TP (True Positive): 74\n",
      "TN (True Negative): 47\n",
      "\n",
      "Rate:\n",
      "FP Ratio: 13.82%\n",
      "FN Ratio: 6.58%\n",
      "TP Ratio: 48.68%\n",
      "TN Ratio: 30.92%\n",
      "\n",
      "Precision: 0.7789\n",
      "Recall: 0.8810\n",
      "F1 Score: 0.8268\n",
      "Accuracy: 0.7961\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('statistics.json', 'r') as f:\n",
    "    statistics = json.load(f)\n",
    "\n",
    "FP = len(statistics.get(\"FP\", []))\n",
    "FN = len(statistics.get(\"FN\", []))\n",
    "TP = len(statistics.get(\"TP\", []))\n",
    "TN = len(statistics.get(\"TN\", []))\n",
    "\n",
    "print(f\"FP (False Positive): {FP}\")\n",
    "print(f\"FN (False Negative): {FN}\")\n",
    "print(f\"TP (True Positive): {TP}\")\n",
    "print(f\"TN (True Negative): {TN}\")\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "total_tasks = FP + FN + TP + TN\n",
    "accuracy = (TP + TN) / total_tasks if total_tasks > 0 else 0\n",
    "\n",
    "FP_ratio = FP / total_tasks if total_tasks > 0 else 0\n",
    "FN_ratio = FN / total_tasks if total_tasks > 0 else 0\n",
    "TP_ratio = TP / total_tasks if total_tasks > 0 else 0\n",
    "TN_ratio = TN / total_tasks if total_tasks > 0 else 0\n",
    "\n",
    "print(f\"\\nRate:\")\n",
    "\n",
    "print(f\"FP Ratio: {FP_ratio:.2%}\")\n",
    "print(f\"FN Ratio: {FN_ratio:.2%}\")\n",
    "print(f\"TP Ratio: {TP_ratio:.2%}\")\n",
    "print(f\"TN Ratio: {TN_ratio:.2%}\")\n",
    "\n",
    "print(f\"\\nPrecision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Case-wise Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy:\n",
      "------------------------------------------------------------\n",
      "Total Cases                    Matches    Accuracy  \n",
      "------------------------------------------------------------\n",
      "152                            121        79.61%\n",
      "\n",
      "Accuracy statistics by next value:\n",
      "------------------------------------------------------------\n",
      "Next Value                     Total      Matches    Accuracy  \n",
      "------------------------------------------------------------\n",
      "FINISH                         68         47         69.12%\n",
      "GEOMATERIAL_COLLECTOR          15         12         80.00%\n",
      "HEATMAP_PLOTTER                28         24         85.71%\n",
      "LOCALITY_COLLECTOR             10         9          90.00%\n",
      "NETWORK_PLOTTER                31         29         93.55%\n",
      "\n",
      "Summary - Ongoing vs Finish:\n",
      "------------------------------------------------------------\n",
      "Status                         Total      Matches    Accuracy  \n",
      "------------------------------------------------------------\n",
      "ongoing                        84         74         88.10%\n",
      "finish                         68         47         69.12%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_next_values(record):\n",
    "    \"\"\"\n",
    "    Extract predicted and expected next values from evaluation_details\n",
    "    \n",
    "    Args:\n",
    "        record: Dictionary containing evaluation details\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (predicted_next, expected_next) or (None, None) if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'evaluation_details' in record:\n",
    "            details = record['evaluation_details']\n",
    "            predicted_next = details['predicted_next']\n",
    "            expected_next = details['expected_next']\n",
    "            return predicted_next, expected_next\n",
    "        return None, None\n",
    "        \n",
    "    except (KeyError, AttributeError, TypeError):\n",
    "        return None, None\n",
    "\n",
    "def calculate_accuracy_by_next(json_file):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for each unique expected next value\n",
    "    \n",
    "    Args:\n",
    "        json_file (str): Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (results for each next, results for ongoing vs finish, overall stats)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(\"JSON data should be a list of records\")\n",
    "        \n",
    "        # Initialize counters\n",
    "        stats = defaultdict(lambda: {\"total\": 0, \"matches\": 0})\n",
    "        status_stats = {\n",
    "            \"ongoing\": {\"total\": 0, \"matches\": 0},\n",
    "            \"finish\": {\"total\": 0, \"matches\": 0}\n",
    "        }\n",
    "        overall_stats = {\"total\": 0, \"matches\": 0}\n",
    "        \n",
    "        # Count matches\n",
    "        for record in data:\n",
    "            predicted_next, expected_next = get_next_values(record)\n",
    "            \n",
    "            if expected_next is not None:\n",
    "                # Update overall statistics\n",
    "                overall_stats[\"total\"] += 1\n",
    "                if predicted_next is not None and predicted_next == expected_next:\n",
    "                    overall_stats[\"matches\"] += 1\n",
    "                \n",
    "                # Count for individual next values based on expected_next\n",
    "                stats[expected_next][\"total\"] += 1\n",
    "                if predicted_next is not None and predicted_next == expected_next:\n",
    "                    stats[expected_next][\"matches\"] += 1\n",
    "                \n",
    "                # Count for ongoing vs finish based on expected_next\n",
    "                status = \"finish\" if expected_next.lower() == \"finish\" else \"ongoing\"\n",
    "                status_stats[status][\"total\"] += 1\n",
    "                if predicted_next is not None and predicted_next == expected_next:\n",
    "                    status_stats[status][\"matches\"] += 1\n",
    "        \n",
    "        # Calculate accuracy for each next value\n",
    "        results = {}\n",
    "        for next_value, counts in stats.items():\n",
    "            accuracy = counts[\"matches\"] / counts[\"total\"] if counts[\"total\"] > 0 else 0\n",
    "            results[next_value] = {\n",
    "                \"total\": counts[\"total\"],\n",
    "                \"matches\": counts[\"matches\"],\n",
    "                \"accuracy\": accuracy\n",
    "            }\n",
    "        \n",
    "        # Calculate accuracy for ongoing vs finish\n",
    "        status_results = {}\n",
    "        for status, counts in status_stats.items():\n",
    "            accuracy = counts[\"matches\"] / counts[\"total\"] if counts[\"total\"] > 0 else 0\n",
    "            status_results[status] = {\n",
    "                \"total\": counts[\"total\"],\n",
    "                \"matches\": counts[\"matches\"],\n",
    "                \"accuracy\": accuracy\n",
    "            }\n",
    "        \n",
    "        # Calculate overall accuracy\n",
    "        overall_accuracy = overall_stats[\"matches\"] / overall_stats[\"total\"] if overall_stats[\"total\"] > 0 else 0\n",
    "        overall_results = {\n",
    "            \"total\": overall_stats[\"total\"],\n",
    "            \"matches\": overall_stats[\"matches\"],\n",
    "            \"accuracy\": overall_accuracy\n",
    "        }\n",
    "        \n",
    "        return results, status_results, overall_results\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {json_file} not found\")\n",
    "        return {}, {}, {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON format\")\n",
    "        return {}, {}, {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {}, {}, {}\n",
    "\n",
    "def main():\n",
    "    json_file = \"evaluated_tasks.json\"\n",
    "    results, status_results, overall_results = calculate_accuracy_by_next(json_file)\n",
    "\n",
    "    # Print overall accuracy first\n",
    "    print(\"\\nOverall Accuracy:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Total Cases':<30} {'Matches':<10} {'Accuracy':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{overall_results['total']:<30} {overall_results['matches']:<10} {overall_results['accuracy']:.2%}\")\n",
    "\n",
    "    # Print detailed results for each next value\n",
    "    print(\"\\nAccuracy statistics by next value:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Next Value':<30} {'Total':<10} {'Matches':<10} {'Accuracy':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for next_value, stats in sorted(results.items()):\n",
    "        print(f\"{next_value:<30} {stats['total']:<10} {stats['matches']:<10} {stats['accuracy']:.2%}\")\n",
    "\n",
    "    # Print summary for ongoing vs finish\n",
    "    print(\"\\nSummary - Ongoing vs Finish:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Status':<30} {'Total':<10} {'Matches':<10} {'Accuracy':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for status, stats in status_results.items():\n",
    "        print(f\"{status:<30} {stats['total']:<10} {stats['matches']:<10} {stats['accuracy']:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
